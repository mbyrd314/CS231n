{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train data shape: ', (49000, 3073))\n",
      "('Train labels shape: ', (49000,))\n",
      "('Validation data shape: ', (1000, 3073))\n",
      "('Validation labels shape: ', (1000,))\n",
      "('Test data shape: ', (1000, 3073))\n",
      "('Test labels shape: ', (1000,))\n",
      "('dev data shape: ', (500, 3073))\n",
      "('dev labels shape: ', (500,))\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "  \"\"\"\n",
    "  Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "  it for the linear classifier. These are the same steps as we used for the\n",
    "  SVM, but condensed to a single function.  \n",
    "  \"\"\"\n",
    "  # Load the raw CIFAR-10 data\n",
    "  cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "  X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "  \n",
    "  # subsample the data\n",
    "  mask = list(range(num_training, num_training + num_validation))\n",
    "  X_val = X_train[mask]\n",
    "  y_val = y_train[mask]\n",
    "  mask = list(range(num_training))\n",
    "  X_train = X_train[mask]\n",
    "  y_train = y_train[mask]\n",
    "  mask = list(range(num_test))\n",
    "  X_test = X_test[mask]\n",
    "  y_test = y_test[mask]\n",
    "  mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "  X_dev = X_train[mask]\n",
    "  y_dev = y_train[mask]\n",
    "  \n",
    "  # Preprocessing: reshape the image data into rows\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "  X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "  X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "  X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "  \n",
    "  # Normalize the data: subtract the mean image\n",
    "  mean_image = np.mean(X_train, axis = 0)\n",
    "  X_train -= mean_image\n",
    "  X_val -= mean_image\n",
    "  X_test -= mean_image\n",
    "  X_dev -= mean_image\n",
    "  \n",
    "  # add bias dimension and transform into columns\n",
    "  X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "  X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "  X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "  X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "  \n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.343987\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -2.600592 analytic: -2.600592, relative error: 1.837773e-08\n",
      "numerical: -0.587039 analytic: -0.587039, relative error: 2.315752e-08\n",
      "numerical: 1.032407 analytic: 1.032407, relative error: 8.815245e-08\n",
      "numerical: -3.029746 analytic: -3.029746, relative error: 2.389078e-08\n",
      "numerical: -2.300399 analytic: -2.300399, relative error: 1.350025e-08\n",
      "numerical: 0.339294 analytic: 0.339294, relative error: 8.585686e-09\n",
      "numerical: 0.268385 analytic: 0.268385, relative error: 3.138395e-07\n",
      "numerical: 0.916889 analytic: 0.916889, relative error: 2.404270e-08\n",
      "numerical: -1.430030 analytic: -1.430030, relative error: 4.823170e-08\n",
      "numerical: 1.442697 analytic: 1.442697, relative error: 1.114059e-08\n",
      "numerical: -0.493673 analytic: -0.493673, relative error: 1.759779e-08\n",
      "numerical: 1.697230 analytic: 1.697230, relative error: 2.641896e-08\n",
      "numerical: 0.510175 analytic: 0.510175, relative error: 1.328652e-07\n",
      "numerical: -0.012809 analytic: -0.012809, relative error: 6.828251e-07\n",
      "numerical: 0.529859 analytic: 0.529859, relative error: 2.026835e-08\n",
      "numerical: -1.158253 analytic: -1.158253, relative error: 1.299719e-08\n",
      "numerical: 1.294226 analytic: 1.294226, relative error: 3.206674e-08\n",
      "numerical: -0.344939 analytic: -0.344939, relative error: 9.631142e-08\n",
      "numerical: -3.803767 analytic: -3.803767, relative error: 3.491044e-09\n",
      "numerical: 0.098168 analytic: 0.098168, relative error: 8.356770e-07\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 1e2)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 1e2)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.343987e+00 computed in 0.520661s\n",
      "vectorized loss: 2.375884e+00 computed in 0.014913s\n",
      "Loss difference: 0.031897\n",
      "Gradient difference: 22.127353\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 5000: loss 763.169024\n",
      "iteration 100 / 5000: loss 564.633772\n",
      "iteration 200 / 5000: loss 418.098339\n",
      "iteration 300 / 5000: loss 310.310459\n",
      "iteration 400 / 5000: loss 230.031243\n",
      "iteration 500 / 5000: loss 170.545445\n",
      "iteration 600 / 5000: loss 126.800787\n",
      "iteration 700 / 5000: loss 94.338266\n",
      "iteration 800 / 5000: loss 70.414130\n",
      "iteration 900 / 5000: loss 52.653186\n",
      "iteration 1000 / 5000: loss 39.521796\n",
      "iteration 1100 / 5000: loss 29.768161\n",
      "iteration 1200 / 5000: loss 22.756257\n",
      "iteration 1300 / 5000: loss 17.313072\n",
      "iteration 1400 / 5000: loss 13.442730\n",
      "iteration 1500 / 5000: loss 10.512834\n",
      "iteration 1600 / 5000: loss 8.399593\n",
      "iteration 1700 / 5000: loss 6.771810\n",
      "iteration 1800 / 5000: loss 5.777399\n",
      "iteration 1900 / 5000: loss 4.915986\n",
      "iteration 2000 / 5000: loss 4.423116\n",
      "iteration 2100 / 5000: loss 3.890816\n",
      "iteration 2200 / 5000: loss 3.425545\n",
      "iteration 2300 / 5000: loss 3.467797\n",
      "iteration 2400 / 5000: loss 3.090686\n",
      "iteration 2500 / 5000: loss 2.964572\n",
      "iteration 2600 / 5000: loss 2.908521\n",
      "iteration 2700 / 5000: loss 2.814371\n",
      "iteration 2800 / 5000: loss 3.006578\n",
      "iteration 2900 / 5000: loss 2.613064\n",
      "iteration 3000 / 5000: loss 2.929422\n",
      "iteration 3100 / 5000: loss 2.824501\n",
      "iteration 3200 / 5000: loss 2.933656\n",
      "iteration 3300 / 5000: loss 2.694639\n",
      "iteration 3400 / 5000: loss 2.711728\n",
      "iteration 3500 / 5000: loss 2.630396\n",
      "iteration 3600 / 5000: loss 2.833367\n",
      "iteration 3700 / 5000: loss 2.634796\n",
      "iteration 3800 / 5000: loss 2.887952\n",
      "iteration 3900 / 5000: loss 3.279124\n",
      "iteration 4000 / 5000: loss 2.970780\n",
      "iteration 4100 / 5000: loss 2.643536\n",
      "iteration 4200 / 5000: loss 3.102881\n",
      "iteration 4300 / 5000: loss 3.120139\n",
      "iteration 4400 / 5000: loss 2.666225\n",
      "iteration 4500 / 5000: loss 2.689122\n",
      "iteration 4600 / 5000: loss 2.719229\n",
      "iteration 4700 / 5000: loss 2.939325\n",
      "iteration 4800 / 5000: loss 2.980570\n",
      "iteration 4900 / 5000: loss 3.120439\n",
      "iteration 0 / 5000: loss 7637.235364\n",
      "iteration 100 / 5000: loss 373.439469\n",
      "iteration 200 / 5000: loss 20.322828\n",
      "iteration 300 / 5000: loss 3.132049\n",
      "iteration 400 / 5000: loss 2.286562\n",
      "iteration 500 / 5000: loss 2.251637\n",
      "iteration 600 / 5000: loss 2.262699\n",
      "iteration 700 / 5000: loss 2.280654\n",
      "iteration 800 / 5000: loss 2.245398\n",
      "iteration 900 / 5000: loss 2.276887\n",
      "iteration 1000 / 5000: loss 2.263221\n",
      "iteration 1100 / 5000: loss 2.293745\n",
      "iteration 1200 / 5000: loss 2.308114\n",
      "iteration 1300 / 5000: loss 2.296544\n",
      "iteration 1400 / 5000: loss 2.256887\n",
      "iteration 1500 / 5000: loss 2.291536\n",
      "iteration 1600 / 5000: loss 2.269967\n",
      "iteration 1700 / 5000: loss 2.247665\n",
      "iteration 1800 / 5000: loss 2.252430\n",
      "iteration 1900 / 5000: loss 2.270936\n",
      "iteration 2000 / 5000: loss 2.252579\n",
      "iteration 2100 / 5000: loss 2.295860\n",
      "iteration 2200 / 5000: loss 2.264560\n",
      "iteration 2300 / 5000: loss 2.278792\n",
      "iteration 2400 / 5000: loss 2.253578\n",
      "iteration 2500 / 5000: loss 2.277348\n",
      "iteration 2600 / 5000: loss 2.260566\n",
      "iteration 2700 / 5000: loss 2.267491\n",
      "iteration 2800 / 5000: loss 2.253348\n",
      "iteration 2900 / 5000: loss 2.293047\n",
      "iteration 3000 / 5000: loss 2.263148\n",
      "iteration 3100 / 5000: loss 2.217164\n",
      "iteration 3200 / 5000: loss 2.292616\n",
      "iteration 3300 / 5000: loss 2.281824\n",
      "iteration 3400 / 5000: loss 2.298535\n",
      "iteration 3500 / 5000: loss 2.240106\n",
      "iteration 3600 / 5000: loss 2.280887\n",
      "iteration 3700 / 5000: loss 2.297956\n",
      "iteration 3800 / 5000: loss 2.275630\n",
      "iteration 3900 / 5000: loss 2.246749\n",
      "iteration 4000 / 5000: loss 2.236323\n",
      "iteration 4100 / 5000: loss 2.267076\n",
      "iteration 4200 / 5000: loss 2.249362\n",
      "iteration 4300 / 5000: loss 2.292454\n",
      "iteration 4400 / 5000: loss 2.268310\n",
      "iteration 4500 / 5000: loss 2.241597\n",
      "iteration 4600 / 5000: loss 2.264802\n",
      "iteration 4700 / 5000: loss 2.259025\n",
      "iteration 4800 / 5000: loss 2.279552\n",
      "iteration 4900 / 5000: loss 2.264257\n",
      "iteration 0 / 5000: loss 76771.649940\n",
      "iteration 100 / 5000: loss 2.294564\n",
      "iteration 200 / 5000: loss 2.293682\n",
      "iteration 300 / 5000: loss 2.292854\n",
      "iteration 400 / 5000: loss 2.294710\n",
      "iteration 500 / 5000: loss 2.293721\n",
      "iteration 600 / 5000: loss 2.294925\n",
      "iteration 700 / 5000: loss 2.293270\n",
      "iteration 800 / 5000: loss 2.296522\n",
      "iteration 900 / 5000: loss 2.293999\n",
      "iteration 1000 / 5000: loss 2.294729\n",
      "iteration 1100 / 5000: loss 2.296271\n",
      "iteration 1200 / 5000: loss 2.292780\n",
      "iteration 1300 / 5000: loss 2.297726\n",
      "iteration 1400 / 5000: loss 2.295607\n",
      "iteration 1500 / 5000: loss 2.298577\n",
      "iteration 1600 / 5000: loss 2.297543\n",
      "iteration 1700 / 5000: loss 2.295252\n",
      "iteration 1800 / 5000: loss 2.296567\n",
      "iteration 1900 / 5000: loss 2.297572\n",
      "iteration 2000 / 5000: loss 2.295119\n",
      "iteration 2100 / 5000: loss 2.295980\n",
      "iteration 2200 / 5000: loss 2.296424\n",
      "iteration 2300 / 5000: loss 2.294270\n",
      "iteration 2400 / 5000: loss 2.295556\n",
      "iteration 2500 / 5000: loss 2.299206\n",
      "iteration 2600 / 5000: loss 2.296111\n",
      "iteration 2700 / 5000: loss 2.294459\n",
      "iteration 2800 / 5000: loss 2.298859\n",
      "iteration 2900 / 5000: loss 2.298361\n",
      "iteration 3000 / 5000: loss 2.296056\n",
      "iteration 3100 / 5000: loss 2.293988\n",
      "iteration 3200 / 5000: loss 2.296821\n",
      "iteration 3300 / 5000: loss 2.293378\n",
      "iteration 3400 / 5000: loss 2.295736\n",
      "iteration 3500 / 5000: loss 2.297915\n",
      "iteration 3600 / 5000: loss 2.296702\n",
      "iteration 3700 / 5000: loss 2.298041\n",
      "iteration 3800 / 5000: loss 2.296889\n",
      "iteration 3900 / 5000: loss 2.292689\n",
      "iteration 4000 / 5000: loss 2.294266\n",
      "iteration 4100 / 5000: loss 2.295886\n",
      "iteration 4200 / 5000: loss 2.298922\n",
      "iteration 4300 / 5000: loss 2.298875\n",
      "iteration 4400 / 5000: loss 2.294328\n",
      "iteration 4500 / 5000: loss 2.296182\n",
      "iteration 4600 / 5000: loss 2.298077\n",
      "iteration 4700 / 5000: loss 2.297863\n",
      "iteration 4800 / 5000: loss 2.297448\n",
      "iteration 4900 / 5000: loss 2.295055\n",
      "iteration 0 / 5000: loss 123854.834063\n",
      "iteration 100 / 5000: loss 2.295615\n",
      "iteration 200 / 5000: loss 2.298277\n",
      "iteration 300 / 5000: loss 2.298211\n",
      "iteration 400 / 5000: loss 2.298411\n",
      "iteration 500 / 5000: loss 2.295593\n",
      "iteration 600 / 5000: loss 2.297883\n",
      "iteration 700 / 5000: loss 2.296161\n",
      "iteration 800 / 5000: loss 2.297483\n",
      "iteration 900 / 5000: loss 2.298013\n",
      "iteration 1000 / 5000: loss 2.297604\n",
      "iteration 1100 / 5000: loss 2.297422\n",
      "iteration 1200 / 5000: loss 2.298651\n",
      "iteration 1300 / 5000: loss 2.296592\n",
      "iteration 1400 / 5000: loss 2.295572\n",
      "iteration 1500 / 5000: loss 2.299958\n",
      "iteration 1600 / 5000: loss 2.298182\n",
      "iteration 1700 / 5000: loss 2.298043\n",
      "iteration 1800 / 5000: loss 2.295763\n",
      "iteration 1900 / 5000: loss 2.295932\n",
      "iteration 2000 / 5000: loss 2.297527\n",
      "iteration 2100 / 5000: loss 2.298153\n",
      "iteration 2200 / 5000: loss 2.297885\n",
      "iteration 2300 / 5000: loss 2.298068\n",
      "iteration 2400 / 5000: loss 2.299362\n",
      "iteration 2500 / 5000: loss 2.296617\n",
      "iteration 2600 / 5000: loss 2.298136\n",
      "iteration 2700 / 5000: loss 2.295641\n",
      "iteration 2800 / 5000: loss 2.298563\n",
      "iteration 2900 / 5000: loss 2.299696\n",
      "iteration 3000 / 5000: loss 2.296342\n",
      "iteration 3100 / 5000: loss 2.298607\n",
      "iteration 3200 / 5000: loss 2.299311\n",
      "iteration 3300 / 5000: loss 2.300625\n",
      "iteration 3400 / 5000: loss 2.298210\n",
      "iteration 3500 / 5000: loss 2.297216\n",
      "iteration 3600 / 5000: loss 2.295190\n",
      "iteration 3700 / 5000: loss 2.297774\n",
      "iteration 3800 / 5000: loss 2.299879\n",
      "iteration 3900 / 5000: loss 2.298371\n",
      "iteration 4000 / 5000: loss 2.297680\n",
      "iteration 4100 / 5000: loss 2.298048\n",
      "iteration 4200 / 5000: loss 2.298216\n",
      "iteration 4300 / 5000: loss 2.298727\n",
      "iteration 4400 / 5000: loss 2.298278\n",
      "iteration 4500 / 5000: loss 2.296984\n",
      "iteration 4600 / 5000: loss 2.298163\n",
      "iteration 4700 / 5000: loss 2.300359\n",
      "iteration 4800 / 5000: loss 2.300168\n",
      "iteration 4900 / 5000: loss 2.300128\n",
      "iteration 0 / 5000: loss 769.927959\n",
      "iteration 100 / 5000: loss 467.097877\n",
      "iteration 200 / 5000: loss 283.766126\n",
      "iteration 300 / 5000: loss 172.278425\n",
      "iteration 400 / 5000: loss 105.340898\n",
      "iteration 500 / 5000: loss 64.561573\n",
      "iteration 600 / 5000: loss 40.226925\n",
      "iteration 700 / 5000: loss 25.291001\n",
      "iteration 800 / 5000: loss 16.342229\n",
      "iteration 900 / 5000: loss 10.927972\n",
      "iteration 1000 / 5000: loss 7.679123\n",
      "iteration 1100 / 5000: loss 5.728333\n",
      "iteration 1200 / 5000: loss 4.683476\n",
      "iteration 1300 / 5000: loss 4.029791\n",
      "iteration 1400 / 5000: loss 3.419636\n",
      "iteration 1500 / 5000: loss 3.258322\n",
      "iteration 1600 / 5000: loss 3.204438\n",
      "iteration 1700 / 5000: loss 2.818055\n",
      "iteration 1800 / 5000: loss 3.122113\n",
      "iteration 1900 / 5000: loss 2.649913\n",
      "iteration 2000 / 5000: loss 2.800829\n",
      "iteration 2100 / 5000: loss 2.723239\n",
      "iteration 2200 / 5000: loss 2.721834\n",
      "iteration 2300 / 5000: loss 3.151575\n",
      "iteration 2400 / 5000: loss 3.202070\n",
      "iteration 2500 / 5000: loss 2.925001\n",
      "iteration 2600 / 5000: loss 3.085051\n",
      "iteration 2700 / 5000: loss 3.245912\n",
      "iteration 2800 / 5000: loss 2.893360\n",
      "iteration 2900 / 5000: loss 3.114387\n",
      "iteration 3000 / 5000: loss 2.958327\n",
      "iteration 3100 / 5000: loss 2.758348\n",
      "iteration 3200 / 5000: loss 3.036924\n",
      "iteration 3300 / 5000: loss 3.057734\n",
      "iteration 3400 / 5000: loss 3.300444\n",
      "iteration 3500 / 5000: loss 3.353406\n",
      "iteration 3600 / 5000: loss 2.943175\n",
      "iteration 3700 / 5000: loss 3.070362\n",
      "iteration 3800 / 5000: loss 3.299453\n",
      "iteration 3900 / 5000: loss 3.235847\n",
      "iteration 4000 / 5000: loss 3.301992\n",
      "iteration 4100 / 5000: loss 2.952111\n",
      "iteration 4200 / 5000: loss 3.395904\n",
      "iteration 4300 / 5000: loss 3.173061\n",
      "iteration 4400 / 5000: loss 3.579167\n",
      "iteration 4500 / 5000: loss 3.021753\n",
      "iteration 4600 / 5000: loss 2.874269\n",
      "iteration 4700 / 5000: loss 2.945236\n",
      "iteration 4800 / 5000: loss 2.984677\n",
      "iteration 4900 / 5000: loss 3.261384\n",
      "iteration 0 / 5000: loss 7673.696244\n",
      "iteration 100 / 5000: loss 50.670217\n",
      "iteration 200 / 5000: loss 2.573908\n",
      "iteration 300 / 5000: loss 2.302164\n",
      "iteration 400 / 5000: loss 2.265273\n",
      "iteration 500 / 5000: loss 2.259529\n",
      "iteration 600 / 5000: loss 2.262694\n",
      "iteration 700 / 5000: loss 2.265819\n",
      "iteration 800 / 5000: loss 2.230836\n",
      "iteration 900 / 5000: loss 2.281280\n",
      "iteration 1000 / 5000: loss 2.254020\n",
      "iteration 1100 / 5000: loss 2.276647\n",
      "iteration 1200 / 5000: loss 2.269680\n",
      "iteration 1300 / 5000: loss 2.252629\n",
      "iteration 1400 / 5000: loss 2.273327\n",
      "iteration 1500 / 5000: loss 2.282720\n",
      "iteration 1600 / 5000: loss 2.252813\n",
      "iteration 1700 / 5000: loss 2.249720\n",
      "iteration 1800 / 5000: loss 2.257505\n",
      "iteration 1900 / 5000: loss 2.252208\n",
      "iteration 2000 / 5000: loss 2.285541\n",
      "iteration 2100 / 5000: loss 2.286813\n",
      "iteration 2200 / 5000: loss 2.274279\n",
      "iteration 2300 / 5000: loss 2.301328\n",
      "iteration 2400 / 5000: loss 2.301043\n",
      "iteration 2500 / 5000: loss 2.284128\n",
      "iteration 2600 / 5000: loss 2.263829\n",
      "iteration 2700 / 5000: loss 2.315962\n",
      "iteration 2800 / 5000: loss 2.269345\n",
      "iteration 2900 / 5000: loss 2.267444\n",
      "iteration 3000 / 5000: loss 2.264995\n",
      "iteration 3100 / 5000: loss 2.255703\n",
      "iteration 3200 / 5000: loss 2.286502\n",
      "iteration 3300 / 5000: loss 2.310817\n",
      "iteration 3400 / 5000: loss 2.266134\n",
      "iteration 3500 / 5000: loss 2.264487\n",
      "iteration 3600 / 5000: loss 2.301471\n",
      "iteration 3700 / 5000: loss 2.260314\n",
      "iteration 3800 / 5000: loss 2.259012\n",
      "iteration 3900 / 5000: loss 2.283305\n",
      "iteration 4000 / 5000: loss 2.304806\n",
      "iteration 4100 / 5000: loss 2.243464\n",
      "iteration 4200 / 5000: loss 2.283284\n",
      "iteration 4300 / 5000: loss 2.275211\n",
      "iteration 4400 / 5000: loss 2.287495\n",
      "iteration 4500 / 5000: loss 2.277168\n",
      "iteration 4600 / 5000: loss 2.285808\n",
      "iteration 4700 / 5000: loss 2.301700\n",
      "iteration 4800 / 5000: loss 2.295906\n",
      "iteration 4900 / 5000: loss 2.272028\n",
      "iteration 0 / 5000: loss 78460.201061\n",
      "iteration 100 / 5000: loss 2.298993\n",
      "iteration 200 / 5000: loss 2.294605\n",
      "iteration 300 / 5000: loss 2.295299\n",
      "iteration 400 / 5000: loss 2.293042\n",
      "iteration 500 / 5000: loss 2.294755\n",
      "iteration 600 / 5000: loss 2.299606\n",
      "iteration 700 / 5000: loss 2.295355\n",
      "iteration 800 / 5000: loss 2.292402\n",
      "iteration 900 / 5000: loss 2.298544\n",
      "iteration 1000 / 5000: loss 2.295286\n",
      "iteration 1100 / 5000: loss 2.295538\n",
      "iteration 1200 / 5000: loss 2.295874\n",
      "iteration 1300 / 5000: loss 2.295293\n",
      "iteration 1400 / 5000: loss 2.288649\n",
      "iteration 1500 / 5000: loss 2.294599\n",
      "iteration 1600 / 5000: loss 2.294385\n",
      "iteration 1700 / 5000: loss 2.301258\n",
      "iteration 1800 / 5000: loss 2.291217\n",
      "iteration 1900 / 5000: loss 2.298314\n",
      "iteration 2000 / 5000: loss 2.291050\n",
      "iteration 2100 / 5000: loss 2.295030\n",
      "iteration 2200 / 5000: loss 2.296643\n",
      "iteration 2300 / 5000: loss 2.297728\n",
      "iteration 2400 / 5000: loss 2.293119\n",
      "iteration 2500 / 5000: loss 2.291652\n",
      "iteration 2600 / 5000: loss 2.300104\n",
      "iteration 2700 / 5000: loss 2.295440\n",
      "iteration 2800 / 5000: loss 2.302623\n",
      "iteration 2900 / 5000: loss 2.294289\n",
      "iteration 3000 / 5000: loss 2.294446\n",
      "iteration 3100 / 5000: loss 2.302149\n",
      "iteration 3200 / 5000: loss 2.295228\n",
      "iteration 3300 / 5000: loss 2.295928\n",
      "iteration 3400 / 5000: loss 2.293213\n",
      "iteration 3500 / 5000: loss 2.294790\n",
      "iteration 3600 / 5000: loss 2.294815\n",
      "iteration 3700 / 5000: loss 2.293145\n",
      "iteration 3800 / 5000: loss 2.296920\n",
      "iteration 3900 / 5000: loss 2.296833\n",
      "iteration 4000 / 5000: loss 2.293822\n",
      "iteration 4100 / 5000: loss 2.290814\n",
      "iteration 4200 / 5000: loss 2.294556\n",
      "iteration 4300 / 5000: loss 2.298075\n",
      "iteration 4400 / 5000: loss 2.303547\n",
      "iteration 4500 / 5000: loss 2.296082\n",
      "iteration 4600 / 5000: loss 2.296867\n",
      "iteration 4700 / 5000: loss 2.299256\n",
      "iteration 4800 / 5000: loss 2.294169\n",
      "iteration 4900 / 5000: loss 2.294951\n",
      "iteration 0 / 5000: loss 124108.958733\n",
      "iteration 100 / 5000: loss 2.296283\n",
      "iteration 200 / 5000: loss 2.298933\n",
      "iteration 300 / 5000: loss 2.299102\n",
      "iteration 400 / 5000: loss 2.299371\n",
      "iteration 500 / 5000: loss 2.295824\n",
      "iteration 600 / 5000: loss 2.294552\n",
      "iteration 700 / 5000: loss 2.298607\n",
      "iteration 800 / 5000: loss 2.299265\n",
      "iteration 900 / 5000: loss 2.298914\n",
      "iteration 1000 / 5000: loss 2.304268\n",
      "iteration 1100 / 5000: loss 2.296073\n",
      "iteration 1200 / 5000: loss 2.296119\n",
      "iteration 1300 / 5000: loss 2.297799\n",
      "iteration 1400 / 5000: loss 2.299410\n",
      "iteration 1500 / 5000: loss 2.297294\n",
      "iteration 1600 / 5000: loss 2.298350\n",
      "iteration 1700 / 5000: loss 2.303723\n",
      "iteration 1800 / 5000: loss 2.299456\n",
      "iteration 1900 / 5000: loss 2.293517\n",
      "iteration 2000 / 5000: loss 2.295359\n",
      "iteration 2100 / 5000: loss 2.299727\n",
      "iteration 2200 / 5000: loss 2.299076\n",
      "iteration 2300 / 5000: loss 2.296970\n",
      "iteration 2400 / 5000: loss 2.299368\n",
      "iteration 2500 / 5000: loss 2.300483\n",
      "iteration 2600 / 5000: loss 2.300140\n",
      "iteration 2700 / 5000: loss 2.298812\n",
      "iteration 2800 / 5000: loss 2.297764\n",
      "iteration 2900 / 5000: loss 2.297683\n",
      "iteration 3000 / 5000: loss 2.298718\n",
      "iteration 3100 / 5000: loss 2.300301\n",
      "iteration 3200 / 5000: loss 2.298760\n",
      "iteration 3300 / 5000: loss 2.296638\n",
      "iteration 3400 / 5000: loss 2.296619\n",
      "iteration 3500 / 5000: loss 2.299937\n",
      "iteration 3600 / 5000: loss 2.299571\n",
      "iteration 3700 / 5000: loss 2.297922\n",
      "iteration 3800 / 5000: loss 2.297982\n",
      "iteration 3900 / 5000: loss 2.297860\n",
      "iteration 4000 / 5000: loss 2.300785\n",
      "iteration 4100 / 5000: loss 2.298173\n",
      "iteration 4200 / 5000: loss 2.298429\n",
      "iteration 4300 / 5000: loss 2.297981\n",
      "iteration 4400 / 5000: loss 2.298075\n",
      "iteration 4500 / 5000: loss 2.300584\n",
      "iteration 4600 / 5000: loss 2.300653\n",
      "iteration 4700 / 5000: loss 2.298200\n",
      "iteration 4800 / 5000: loss 2.299120\n",
      "iteration 4900 / 5000: loss 2.298067\n",
      "lr 3.000000e-08 reg 5.000000e+04 train accuracy: 0.203469 val accuracy: 0.207000\n",
      "lr 3.000000e-08 reg 5.000000e+05 train accuracy: 0.258306 val accuracy: 0.273000\n",
      "lr 3.000000e-08 reg 5.000000e+06 train accuracy: 0.246898 val accuracy: 0.262000\n",
      "lr 3.000000e-08 reg 8.000000e+06 train accuracy: 0.244898 val accuracy: 0.246000\n",
      "lr 5.000000e-08 reg 5.000000e+04 train accuracy: 0.196796 val accuracy: 0.203000\n",
      "lr 5.000000e-08 reg 5.000000e+05 train accuracy: 0.251143 val accuracy: 0.273000\n",
      "lr 5.000000e-08 reg 5.000000e+06 train accuracy: 0.239531 val accuracy: 0.254000\n",
      "lr 5.000000e-08 reg 8.000000e+06 train accuracy: 0.246245 val accuracy: 0.240000\n",
      "best validation accuracy achieved during cross-validation: 0.273000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [3e-8, 5e-8]\n",
    "regularization_strengths = [5e4, 5e5, 5e6, 8e6]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "for learning_rate in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        softmax = Softmax()\n",
    "        softmax.train(X_train, y_train, learning_rate=learning_rate, reg=reg, num_iters=5000, verbose=True)\n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        training_accuracy = np.mean(y_train_pred == y_train)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        validation_accuracy = np.mean(y_val_pred == y_val)\n",
    "        results[(learning_rate, reg)] = (training_accuracy, validation_accuracy)\n",
    "        if validation_accuracy > best_val:\n",
    "            best_val = validation_accuracy\n",
    "            best_softmax = softmax\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.267000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAAF/CAYAAABQVS1eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nO3DxJCIiIrKDvwCMszMDZSLo5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc90a15a050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  \n",
    "  # Rescale the weights to be between 0 and 255\n",
    "  wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "  plt.imshow(wimg.astype('uint8'))\n",
    "  plt.axis('off')\n",
    "  plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
